{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Warmup+All (no momentum after warmup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "KERUAEso-4ot",
        "outputId": "301a5a11-c3e0-4ef3-e00c-c33d245a4809"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import log, e\n",
        "import torch.optim as optim\n",
        "import pickle\n",
        "import sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "plt.rcParams.update({'font.size': 20, 'figure.figsize': (8,4.5), 'font.family':'Arial', 'axes.axisbelow':True})\n",
        "\n",
        "torch.manual_seed(22)\n",
        "np.random.seed(22)\n",
        "\n",
        "GROUP_SIZE=0.98\n",
        "NOISE=1/8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PRaqDY21EqrB"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_dim, out_channel, patch_num, small=True):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, out_channel*2, int(input_dim/patch_num), int(input_dim/patch_num))        \n",
        "        if small:\n",
        "            self.conv1.weight = torch.nn.Parameter(self.conv1.weight*0.1) \n",
        "            self.conv1.bias = torch.nn.Parameter(self.conv1.bias*0.1) \n",
        "        self.out_channel = out_channel\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = x**3\n",
        "        x = torch.sum(x,2)\n",
        "        output = torch.stack([torch.sum(x[:,:self.out_channel],1), torch.sum(x[:,self.out_channel:],1)]).transpose(1,0)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i4FIIEJZFKzi"
      },
      "outputs": [],
      "source": [
        "def train(model, criterion, data, labels, optimizers, epochs=100, plot=False, verbose=True):\n",
        "    min_loss = 100\n",
        "    core, spu, loss_list = [], [], []\n",
        "    core_inner, spu_inner = test_inner(model)\n",
        "    core.append(core_inner)\n",
        "    spu.append(spu_inner)\n",
        "\n",
        "    for epoch in range(epochs):  \n",
        "        \n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, labels) \n",
        "        loss_list.append(loss.detach())\n",
        "        loss.backward() \n",
        "        core_inner, spu_inner = test_inner(model)\n",
        "        core.append(core_inner)\n",
        "        spu.append(spu_inner)\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "        \n",
        "        if epoch%100 == 0:\n",
        "            if verbose:\n",
        "                print('Epoch %d --- loss: %.3f' % (epoch + 1, loss.item()))\n",
        "    \n",
        "    core, spu, loss_list = torch.stack(core), torch.stack(spu), torch.stack(loss_list)\n",
        "    print('Finished Training')\n",
        "    return core, spu, loss_list\n",
        "\n",
        "\n",
        "def test(model, criterion, data, labels):\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(data) # ,_\n",
        "        predicted = torch.max(outputs.data, 1).indices\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the %d test images: %.4f %%' % (data.shape[0],\n",
        "        100 * correct / data.shape[0]))\n",
        "    \n",
        "    return 100 * correct / data.shape[0]\n",
        "\n",
        "\n",
        "def test_inner(model):\n",
        "    with torch.no_grad():\n",
        "        core_inner = torch.max(torch.abs(torch.matmul(model.conv1.weight.squeeze(1), \n",
        "                                                      vc.float().unsqueeze(1).cuda())))\n",
        "        spurious_inner = torch.max(torch.abs(torch.matmul(model.conv1.weight.squeeze(1), \n",
        "                                                          vs.float().unsqueeze(1).cuda())))\n",
        "\n",
        "    return core_inner, spurious_inner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9j59uHUT-48V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20000, 150])\n",
            "torch.Size([20000])\n",
            "torch.Size([10000, 1, 150]) torch.Size([10000, 1, 150])\n",
            "torch.Size([10000]) torch.Size([10000])\n"
          ]
        }
      ],
      "source": [
        "DATA_NUM = 10000\n",
        "PATCH_NUM = 3\n",
        "PATCH_LEN = 50\n",
        "\n",
        "def div_norm(x):\n",
        "    x /= np.linalg.norm(x)\n",
        "    return x\n",
        "\n",
        "vc = np.random.randn(PATCH_LEN) \n",
        "vc /= np.linalg.norm(vc)\n",
        "\n",
        "vs = np.random.randn(PATCH_LEN) \n",
        "vs /= np.linalg.norm(vs)\n",
        "vs -= vs.dot(vc) * vc\n",
        "vs /= np.linalg.norm(vs)\n",
        "\n",
        "vc, vs = torch.tensor(vc), torch.tensor(vs)\n",
        "\n",
        "data = []\n",
        "data_visual = []\n",
        "labels = []\n",
        "spurious_labels = []\n",
        "\n",
        "xi_large, xi_small = torch.zeros(PATCH_LEN), torch.zeros(PATCH_LEN)\n",
        "\n",
        "for i in range(DATA_NUM*2):\n",
        "    y = np.random.choice([-1,1], 1)[0] \n",
        "    alpha = np.random.uniform(0,1)\n",
        "\n",
        "    # Feature noise patch\n",
        "    a = (alpha<GROUP_SIZE)*y - (alpha>=GROUP_SIZE)*y\n",
        "    # Noise patch\n",
        "    xi = torch.tensor(np.random.normal(0, NOISE, size=(PATCH_LEN)))\n",
        "    \n",
        "    if a==y:\n",
        "        xi_large+=xi\n",
        "    else:\n",
        "        xi_small+=xi\n",
        "\n",
        "    core = vc*y/5 \n",
        "    spurious = vs*a\n",
        "    x = torch.stack([core, spurious, xi])\n",
        "    \n",
        "    x_visual = torch.stack([core*1.2, spurious, xi])\n",
        "    \n",
        "    x = x.flatten()\n",
        "    x_visual = x_visual.flatten()\n",
        "\n",
        "    data.append(x)\n",
        "    data_visual.append(x_visual)\n",
        "    labels.append(y)\n",
        "    spurious_labels.append(a)\n",
        "\n",
        "data = torch.stack(data)\n",
        "data_visual = torch.stack(data_visual)\n",
        "print(data.shape)\n",
        "\n",
        "labels = torch.tensor(labels)\n",
        "spurious_labels = torch.tensor(spurious_labels)\n",
        "labels[labels==-1] = 0\n",
        "spurious_labels[spurious_labels==-1]=0\n",
        "print(labels.shape)\n",
        "\n",
        "training_data = data[:DATA_NUM,:].unsqueeze(1).float().cuda()\n",
        "test_data = data[DATA_NUM:,:].unsqueeze(1).float().cuda()\n",
        "\n",
        "print(training_data.shape, test_data.shape)\n",
        "\n",
        "training_labels = labels[:DATA_NUM].cuda()\n",
        "test_labels = labels[DATA_NUM:].cuda()\n",
        "spurious_training_labels = spurious_labels[:DATA_NUM].cuda()\n",
        "spurious_test_labels = spurious_labels[DATA_NUM:].cuda()\n",
        "print(training_labels.shape, test_labels.shape)\n",
        "\n",
        "training_labels = training_labels.long()\n",
        "test_labels = test_labels.long()\n",
        "spurious_training_labels = spurious_training_labels.long()\n",
        "spurious_test_labels = spurious_test_labels.long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bdCmk6BgEkBO"
      },
      "outputs": [],
      "source": [
        "for i in range(DATA_NUM):\n",
        "    idx = torch.randperm(PATCH_NUM)\n",
        "    stack_data = torch.stack([training_data[i,0,:][j*PATCH_LEN:(j+1)*PATCH_LEN] for j in range(PATCH_NUM)])\n",
        "    stack_data = stack_data[idx].flatten()\n",
        "    training_data[i,0,:] = stack_data\n",
        "\n",
        "    idx = torch.randperm(PATCH_NUM)\n",
        "    stack_data = torch.stack([test_data[i,0,:][j*PATCH_LEN:(j+1)*PATCH_LEN] for j in range(PATCH_NUM)])\n",
        "    stack_data = stack_data[idx].flatten()\n",
        "    test_data[i,0,:] = stack_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "small_test_data = torch.concat([test_data[[x and y for x,y in zip(test_labels==1,spurious_test_labels==0)]],test_data[[x and y for x,y in zip(test_labels==0,spurious_test_labels==1)]]])\n",
        "small_test_label = torch.concat([test_labels[[x and y for x,y in zip(test_labels==1,spurious_test_labels==0)]],test_labels[[x and y for x,y in zip(test_labels==0,spurious_test_labels==1)]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "smallest_group_size = min(len(training_data[[x and y for x,y in zip(training_labels==0,spurious_training_labels==1)]]),len(training_data[[x and y for x,y in zip(training_labels==1,spurious_training_labels==0)]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([424, 1, 150])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "warmup_data = []\n",
        "warmup_data.append(training_data[[x and y for x,y in zip(training_labels==0,spurious_training_labels==0)]][:smallest_group_size])\n",
        "warmup_data.append(training_data[[x and y for x,y in zip(training_labels==1,spurious_training_labels==0)]][:smallest_group_size])\n",
        "warmup_data.append(training_data[[x and y for x,y in zip(training_labels==0,spurious_training_labels==1)]][:smallest_group_size])\n",
        "warmup_data.append(training_data[[x and y for x,y in zip(training_labels==1,spurious_training_labels==1)]][:smallest_group_size])\n",
        "warmup_data = torch.concat(warmup_data)\n",
        "\n",
        "warmup_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([424])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "warmup_labels = []\n",
        "warmup_labels.append(training_labels[[x and y for x,y in zip(training_labels==0,spurious_training_labels==0)]][:smallest_group_size])\n",
        "warmup_labels.append(training_labels[[x and y for x,y in zip(training_labels==1,spurious_training_labels==0)]][:smallest_group_size])\n",
        "warmup_labels.append(training_labels[[x and y for x,y in zip(training_labels==0,spurious_training_labels==1)]][:smallest_group_size])\n",
        "warmup_labels.append(training_labels[[x and y for x,y in zip(training_labels==1,spurious_training_labels==1)]][:smallest_group_size])\n",
        "warmup_labels = torch.concat(warmup_labels)\n",
        "\n",
        "warmup_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1xTgYmxxF0H7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 72.3800 %\n",
            "Epoch 1 --- loss: 0.693\n",
            "Epoch 101 --- loss: 0.693\n",
            "Epoch 201 --- loss: 0.693\n",
            "Epoch 301 --- loss: 0.693\n",
            "Epoch 401 --- loss: 0.693\n",
            "Epoch 501 --- loss: 0.693\n",
            "Epoch 601 --- loss: 0.692\n",
            "Epoch 701 --- loss: 0.662\n",
            "Epoch 801 --- loss: 0.108\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 92.5500 %\n",
            "Accuracy of the network on the 229 test images: 94.7598 %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "94.75982532751091"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CNN = ConvNet(PATCH_LEN*PATCH_NUM, 20, PATCH_NUM).cuda() #, small=False\n",
        "pred = CNN(test_data)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "test(CNN, criterion, test_data, test_labels)\n",
        "\n",
        "num_epochs = 801\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(CNN.parameters(), lr=0.03, momentum=0.9)\n",
        "\n",
        "core, spu, loss_list = train(CNN, criterion, warmup_data, warmup_labels, [optimizer], num_epochs, plot=False)\n",
        "test(CNN, criterion, test_data, test_labels)\n",
        "test(CNN, criterion, small_test_data, small_test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(CNN.parameters(), lr=0.03)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "woovpBCvI0xM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 --- loss: 0.209\n",
            "Epoch 101 --- loss: 0.042\n",
            "Epoch 201 --- loss: 0.040\n",
            "Epoch 301 --- loss: 0.039\n",
            "Epoch 401 --- loss: 0.038\n",
            "Epoch 501 --- loss: 0.037\n",
            "Epoch 601 --- loss: 0.036\n",
            "Epoch 701 --- loss: 0.036\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 98.8700 %\n",
            "Accuracy of the network on the 229 test images: 67.6856 %\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 701\n",
        "plt.rcParams.update({'figure.figsize': (8,4.5)})\n",
        "\n",
        "core1, spu1, loss_list1 = train(CNN, criterion, training_data, training_labels, [optimizer], num_epochs, plot=False)\n",
        "test(CNN, criterion, test_data, test_labels)\n",
        "test(CNN, criterion, small_test_data, small_test_label)\n",
        "\n",
        "core = torch.concat([core,core1])\n",
        "spu = torch.concat([spu,spu1])\n",
        "loss_list = torch.concat([loss_list,loss_list1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QOBGlDSx9G_l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 98.8700 %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "98.87"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(CNN, criterion, test_data, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 113 test images: 53.9823 %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "53.982300884955755"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(CNN, criterion, test_data[[x and y for x,y in zip(test_labels==1,spurious_test_labels==0)]], test_labels[[x and y for x,y in zip(test_labels==1,spurious_test_labels==0)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 116 test images: 81.0345 %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "81.03448275862068"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(CNN, criterion, test_data[[x and y for x,y in zip(test_labels==0,spurious_test_labels==1)]], test_labels[[x and y for x,y in zip(test_labels==0,spurious_test_labels==1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 229 test images: 67.6856 %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "67.68558951965065"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(CNN, criterion, small_test_data, small_test_label)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('py37')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "e91caccb34bff0363b485688dcad7b14d06d60416c43b5db629aa10f3f224696"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
